\documentclass[a4j]{jarticle} %jsrticleでもいい
\usepackage[utf8]{inputenc} % 文字コードをUTF-8に設定
\usepackage{fancyhdr} %ヘッダーを表示させるのに必要
%\usepackage{listings, jlisting} %ソースコードを貼り付けるのに必要
\usepackage{listings} %ソースコードを貼り付けるのに必要
\usepackage{color}
\usepackage{comment} %複数行のコメントアウトのパッケージ
\usepackage{amsmath,amssymb}
\usepackage[dvipdfmx]{graphicx}
\usepackage{here}
\usepackage{ascmac}
\setlength{\parindent}{0pt}
\lstset{
  basicstyle={\ttfamily},
  backgroundcolor={\color[gray]{.90}},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  breaklines=true,
  columns=[l]{fullflexible},
  %numbers=left, %行番号を表示する
  xrightmargin=1zw,
  xleftmargin=2zw,
  numberstyle={\scriptsize},
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}

\pagestyle{fancy}
  \lhead{言語認知工学 最終レポート} %ヘッダー左
  \rhead{2210259 米谷 祐希} %ヘッダー右
\topmargin =-15mm %ページ上部の隙間の調整

\title{言語認知工学 最終レポート}
\author{2210259 米谷 祐希}
\date{\today} %\todayで今日の日付を取得
\renewcommand{\lstlistingname}{コード}
\begin{document}
\maketitle

\section*{問1} %%%%%%%%%%%%%%%%%%%%
\renewcommand{\labelenumi}{(\arabic{enumi})}
\begin{enumerate}
\item ×~単語 apple の意味を\underline{外界との対応付けで}推測・学習することは，記号接地の一例である．
\item ×~\underline{プロトタイプ}とは，カテゴリーの最も典型的な仮想上のメンバのことである．
\item ×~「数学」と「物理学」は，\underline{同位関係}にある．
\item ×~\underline{BoW}とは，自然言語処理において文書や言語表現を単語の集まりで表現する方法のことである．
\item ◯
\item ◯
\end{enumerate}

\section*{問2}
　単語doctorに対する、単語nurseによるプライミング効果は意味プライミングであるので、その効果を検証するための比較対象としては、プライミングを行わずに単にdoctorと示したり、全く関係ない語を示してdoctorの反応時間を測定し、比較すれば良い。

\section*{問3}
　まず最初に
\begin{equation}
  d_1^m = \frac{\partial E}{\partial z_1^m} = \frac{\partial E}{\partial a}\frac{\partial a}{\partial z_1^m}
\end{equation}
　ここで、シグモイド関数の微分を考えると、
\begin{equation}
  \frac{\partial a}{\partial z_1^m} = f'_0(z) = f_0(z)(1-f_0(z)) = a(1-a)~~~ (\because a = a_1^m = f_0(z_1^m))
\end{equation}
であり、
\begin{equation}
  \frac{\partial E}{\partial a} = -\frac{y}{a} + \frac{1-y}{1-a}
\end{equation}
であるので、
\begin{align*}
  d_1^m &= (-\frac{y}{a} + \frac{1-y}{1-a})a(1-a) \\
  &= -y(1-a)+(1-y)a \\
  &= a-y = a_1^m - y
\end{align*}
と導出できる。

\section*{問4}
　リカレントネットワークは隠れ層の情報を保持して、次の処理へとつなげることができ、文章などの時間軸データとなったいるものに対して利点となっている。一方で、フィードフォワードネットワークは、実装がシンプルであり学習もリカレントネットワークでの勾配消失問題に対して軽減することができるという利点がある。さらに文章分類において、特徴抽出により固定長のベクトルにすることができる場合には、時系列データとして扱う必要がなくなるという点でフィードフォワードネットワークの効率に利点がある。

\section*{問5}
　意味空間モデルにおいて単語というのはベクトルで表される。そのベクトルというのは、その他の単語・文脈からどのように使われるか、再起頻度などによって計算されるものであり、Glenberg and Robertsonが言うように、人間の実世界での意味の認識・獲得の過程と対応付けられていないという点が問題である。例えば犬というものを想像したときに単語ベクトルの「犬」という単語は他の語とどんな関係性にあるという情報を持っているのみであり、実際に人間がふわふわして・小さい・動くもの、のような視覚的であったり感覚的な特徴情報を保持しているわけではないということである。

\section*{問6}
\subsection*{(1)}
$v_{34}$は、文章$D_4$における、単語$w_3$の出現頻度を表している。
\subsection*{(2)}
$v_{34}$は、段落、文、前後数単語のある範囲での、$w_3$と$w_4$が同時に出現する、共起頻度を表している。
\subsection*{(3)}
　$w_1$とコサイン類似度が高い単語は$\dfrac{w_1\cdot w_i}{|w_1|\cdot|w_i|}$が最大となる単語$w_i$を選択すれば良い。\\
計算の結果そうなるものは、単語$w_5$であり、コサイン類似度は、
\begin{equation}
  \dfrac{w_1\cdot w_i}{|w_1|\cdot|w_i|} = \dfrac{37}{\sqrt{78} \cdot \sqrt{26}} = \underline{\dfrac{37}{26\sqrt{3}}}
\end{equation}
となる。
\subsection*{(4)}
　この問題ではtd-idfは$l_{ij}g_i$と表される。これに値を当てはめて計算すると、
\begin{align*}
  l_{ij}g_i &= \log_2 (1+f_{ij})\cdot \log_2(n/n_i) \\
  &= \log_2 (1+6)\cdot \log_2(5/3) \\
  &= \log_2 7 (\log_2 5 - \log_2 3)
\end{align*}
となる。

\section*{問7}
\subsection*{(1)}
　ノードの次数とは、そのノードの接合しているリンク数なので、次数が2次のものは\textbf{\underline{ a,b,e,f}}、である。
\subsection*{(2)}
　それぞれのノード$i$における$C_i$を計算した。
 \begin{table}[H]
    \centering
    \caption{それぞれのノードにおける$C_i$}
    \label{tab:hogehoge}
    \begin{tabular}{cc} \hline
    ノード$i$ & $C_i$ \\ \hline
    a & 1 \\
    b & 1 \\
    c & 1/3 \\
    d & 1/3 \\
    e & 1 \\
    f & 1 \\
    g & 2/3 \\ \hline
    \end{tabular}
\end{table}
よって
\begin{equation}
  C = \dfrac{\Sigma C_i}{|V|} = \dfrac{16}{21}
\end{equation}
\subsection*{(3)}
それぞれのペアについての最短経路長をすべて足し、$_7C_2$で割ると平均最短経路長になるので、
\begin{equation}
  L = \dfrac{34}{21}
\end{equation}
となる。
\section*{問8}
　第6章で扱っている評価方法の中で、これは順位付きの評価であるが、一度6つのすべてを対象として順位なしとして比較すると、どちらのプログラムも6個の出力の中に人間が連想した3つの連想語は含まれている。つまり再現率は100\%である。そして3つの連想後に対して6個の出力をしているので、適合率は50\%である。よって順位なしとして扱った場合の評価はどちらも同じである。\\
　次に順位付きとしてみて、平均適合率を計算する。
\subsection*{プログラムA}
　第2,3,4位にあるので、
\begin{equation}
  (平均適合率) = \dfrac{\tfrac{1}{2}+\tfrac{2}{3}+\tfrac{3}{4}}{3} = \dfrac{23}{36}
\end{equation}
\subsection*{プログラムB}
　第1,4,6位にあるので、
\begin{equation}
  (平均適合率) = \dfrac{\tfrac{1}{1}+\tfrac{2}{4}+\tfrac{3}{6}}{3} = \dfrac{24}{36}
\end{equation}
と言う結果になったので、プログラムBの優れているという評価ができる。

\end{document}

\begin{comment}
\end{comment}